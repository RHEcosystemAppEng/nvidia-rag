imagePullSecret:
  name: "ngc-secret"

ragServer:
  concurrentWorkers: 64
  image:
    repository: quay.io/sauagarw/nvidia-rag-server
    tag: "3.0"
    pullPolicy: IfNotPresent
  name: rag-server
  replicas: 1
  nodeSelector: {}
  tolerations: {}
  affinity: {}
  env:
      EXAMPLE_PATH: 'src/'
      PROMPT_CONFIG_FILE: "/prompt.yaml"
      APP_VECTORSTORE_URL: "http://milvus:19530"
      APP_VECTORSTORE_NAME: "milvus"
      APP_VECTORSTORE_INDEXTYPE: GPU_CAGRA
      COLLECTION_NAME: nvidia_blogs
      APP_LLM_SERVERURL: "nim-llm:8000"
      APP_LLM_MODELNAME: meta/llama-3.1-70b-instruct
      APP_LLM_MODELENGINE: nvidia-ai-endpoints
      APP_EMBEDDINGS_SERVERURL: "nemo-embedding-ms:8000"
      APP_EMBEDDINGS_MODELNAME: nvidia/llama-3.2-nv-embedqa-1b-v2
      APP_EMBEDDINGS_MODELENGINE: nvidia-ai-endpoints
      APP_RANKING_MODELNAME: nvidia/llama-3.2-nv-rerankqa-1b-v2
      APP_RANKING_MODELENGINE: nvidia-ai-endpoints
      APP_RANKING_SERVERURL: "nemo-ranking-ms:8000"
      APP_TEXTSPLITTER_MODELNAME: nvidia/llama-3.2-nv-embedqa-1b-v1
      APP_TEXTSPLITTER_CHUNKSIZE: 2000
      APP_TEXTSPLITTER_CHUNKOVERLAP: 200
      APP_RETRIEVER_SCORETHRESHOLD: 0.25
      CONVERSATION_HISTORY: 5
      APP_RETRIEVER_TOPK: 4
      VECTOR_DB_TOPK: 20
      LOGLEVEL: INFO
      ENABLE_MULTITURN: true
      ENABLE_QUERYREWRITER: true
  service:
      type: NodePort
      targetPort: 8081
      ports:
        - port: 8081
          targetPort: http
          protocol: TCP
          name: http

ragPlayground:
  image:
    repository: quay.io/sauagarw/nvidia-playground
    tag: latest
    pullPolicy: IfNotPresent
  name: rag-playground
  replicas: 1
  nodeSelector: {}
  tolerations: {}
  affinity: {}
  env:
      APP_SERVERURL: "http://rag-server"
      APP_SERVERPORT: 8081
      APP_MODELNAME: meta/llama-3.1-70b-instruct
  service:
      type: NodePort
      targetPort: 8090
      ports:
        - port: 8090
          targetPort: http
          protocol: TCP
          name: http

nvidia-nim-llama-32-nv-embedqa-1b-v2:
  acceleratorName: nvidia.com/gpu
  tolerations:
  - effect: NoSchedule
    key: nvidia.com/gpu
    operator: Exists
  fullnameOverride: "nemo-embedding-ms"
  service:
    name: "nemo-embedding-ms"
  resources:
    limits:
      cpu: '6'
      memory: 24Gi
      nvidia.com/gpu: '1'
    requests:
      cpu: '4'
      memory: 16Gi
      nvidia.com/gpu: '1'
  nim:
    ngcAPIKey: ""
    modelName: 'llama-3.2-nv-embedqa-1b-v2'
    modelVersion: 1.3.1

nim-llm:
  service:
    name: "nim-llm"
  image:
      repository:  nvcr.io/nim/meta/llama-3.1-8b-instruct
      pullPolicy: IfNotPresent
      tag: "1.3.3"
  resources:
    limits:
      cpu: '6'
      memory: 24Gi
      nvidia.com/gpu: '1'
    requests:
      cpu: '4'
      memory: 16Gi
      nvidia.com/gpu: '1'
  nim:
    ngcAPIKey: ""
    modelName: 'llama-3.1-8b-instruct'
    modelVersion: 1.3.3

text-reranking-nim:
  acceleratorName: nvidia.com/gpu
  tolerations:
  - effect: NoSchedule
    key: nvidia.com/gpu
    operator: Exists
  fullnameOverride: "nemo-ranking-ms"
  service:
    name: "nemo-ranking-ms"
  resources:
    limits:
      cpu: '6'
      memory: 24Gi
      nvidia.com/gpu: '1'
    requests:
      cpu: '4'
      memory: 16Gi
      nvidia.com/gpu: '1'
  nim:
    ngcAPIKey: ""
    modelName: 'llama-3.2-nv-rerankqa-1b-v2'
    modelVersion: 1.3.0

milvus:
  service:
    name: "milvus"
  tolerations:
  - effect: NoSchedule
    key: nvidia.com/gpu
    operator: Exists
  standalone:
    resources:
      requests:
        nvidia.com/gpu: 1
      limits:
        nvidia.com/gpu: 1